<html>
<head>
  <meta http-equiv="content-type" content="text/html; charset=UTF-8">
  <title>OpenGL with PySide6</title>
  <link href="css/prism.css" rel="stylesheet">
  <link href="css/pycut.css" rel="stylesheet">
  <link href="css/simpletree.css" rel="stylesheet">
  <script type="text/javascript" src="js/prism.js">
 </script>
  <style>
 .accordion {
  background-color: #eee;
  color: #444;
  cursor: pointer;
  padding: 18px;
  width: 100%;
  border: none;
  text-align: left;
  outline: none;
  font-size: 15px;
  transition: 0.4s;
}

 .active, .accordion:hover {
  background-color: #ccc; 
}

 .panel {
  padding: 0 18px;
  display: none;
  background-color: white;
  overflow: hidden;
}</style>
</head>

<body>
<!-- ----------------------------------------------------------------------------------------------------------->
<!-- ----------------------------------------------------------------------------------------------------------->
<!-- ----------------------------------------------------------------------------------------------------------->
<!-- ----------------------------------------------------------------------------------------------------------->

<div class="sidenav">
<h3 class="title_sidenav">Contents</h3>
<ul class="tree">
  <li><a href="#P-01">Introduction</a></li>
  <li><a href="#P-02">OpenGL Primer</a> 
    <ul class="tree">
      <li><a href="#P-02-01">The graphic pipeline</a></li>
      <li><a href="#P-02-02">Buffers</a></li>
      <li><a href="#P-02-03">Variables</a></li>
    </ul>
  </li>
  <li><a href="#P-03">Preliminaries</a> 
    <ul class="tree">
      <li><a href="#P-03-01">Normalize Device Coords</a></li>
      <li><a href="#P-03-02">Triangulation</a></li>
      <li><a href="#P-03-03">GL Primitives</a></li>
      <li><a href="#P-03-04">Interpolation</a></li>
    </ul>
  </li>
  <li><a href="#P-04">Quick Start</a> 
    <ul class="tree">
      <li><a href="#P-04-01">Writing shaders</a></li>
      <li><a href="#P-04-02">Compiling the program</a></li>
      <li><a href="#P-04-03">Uploading data to the GPU</a></li>
      <li><a href="#P-04-04">Rendering</a></li>
      <li><a href="#P-04-05">Uniform color</a></li>
      <li><a href="#P-04-06">Varying color</a></li>
    </ul>
  </li>
  <li><a href="#P-05">PySide6 - Basic Examples</a>
    <ul class="tree">
      <li><a href="#P-05-01">A blue quad</a></li>
      <li><a href="#P-05-02">A colored quad</a></li>
      <li><a href="#P-05-03">A colored quad - animated</a></li>
      <li><a href="#P-05-04">A cube</a></li>
      <li><a href="#P-05-05">A cube with outlined edges</a></li>
      <li><a href="#P-05-06">A cube with texture</a></li>
    </ul>
  </li>
  <li><a href="#P-06">PySide6 - Handling the mouse </a>
   <ul class="tree">
      <li><a href="#P-06-01">TODO - An improved Widget</a></li>
    </ul>
  </li>
  <li><a href="#P-07">PySide6 - Simulation Widgets</a>
  <ul class="tree">
      <li><a href="#P-07-01">TODO - Slider</a></li>
	  <li><a href="#P-07-02">TODO - Run/Stop Animation</a></li>
    </ul>
  </li>
  <li><a href="#P-08">TODO - PySide6 - Moving the tool along the path</a></li>
  <li><a href="#P-09">TODO - PySide6 - Simulating the milling process</a></li>
</ul>
<script type="text/javascript">
var tree = document.querySelectorAll('ul.tree a:not(:last-child)');
for (var i = 0; i < tree.length; i++){
    tree[i].addEventListener('click', function(e) {
        var parent = e.target.parentElement;
        var classList = parent.classList;
        if (classList.contains("open")) {
            classList.remove('open');
            var opensubs = parent.querySelectorAll(':scope .open');
            for (var i = 0; i < opensubs.length; i++) {
                opensubs[i].classList.remove('open');
            }
        } else {
            classList.add('open');
        }
        if (classList.contains("open")) {
            //e.preventDefault(); // on open -> jump (default)
          
        } else {
            e.preventDefault(); // on close
        }
    });
}</script>
</div>
<!-- ----------------------------------------------------------------------------------------------------------->
<!-- ----------------------------------------------------------------------------------------------------------->
<!-- ----------------------------------------------------------------------------------------------------------->
<!-- ----------------------------------------------------------------------------------------------------------->

<div class="main">
<h1 class="etitle">OpenGL with PySide6</h1>

<h2 id="P-01">Introduction</h2>

<p>This is a small tutorial how to program OpenGL with PySide6. Please note
that I am an absolute OpenGL beginner. I have simply ported
<strong>Candle</strong> GCode viewer from (Qt) c++ to python. This is been a
good introduction in OpenGL for me.</p>

<p>But trying to port <strong>jsCut</strong> gcode simulator (javascript) to
python was something harder. Infact, I have not yet succeeded, althought the
javascript code is only 800 lines of code. There are there 3 different shader
programs with one (or two!) with a texture, that allows to simulate the milling
process. It's quite impressive and unfortunately from the code I have not yet
understood how the texture allows to simulate the milling process. Probably
this is the cause I'm still unsuccessfull...</p>

<p>Moreover I do not believe that the python code will be less that the
javascript code, although this is oft the case when translating javascript to
python. Maybe the webgl API is here particularely well designed and compact.</p>

<p>This led me to write this small tutorial. I am picking for it from the
internet the pages I found interesting and best explained.</p>
<ul>
  <li><a href="https://www.labri.fr/perso/nrougier/python-opengl/"><span
    style="color:#8000ff">Python &amp; OpenGL for Scientific
    Visualization</span></a></li>
  <li><a href="https://ghorwin.github.io/OpenGLWithQt-Tutorial/"><span
    style="color:#8000ff">OpenGL + Qt Tutorial </span></a></li>
</ul>

<p>The first is an excellent introduction to OpenGL, but unfortunately it
diverges from its goal after the first chapters. It uses its own magic "glumpy"
library to encapsulate most of OpenGL, for me too much python magic. But most
important, it does not explain how to use the glumpy/gloo magic inside an
PySide (Qt) application. And further, the tutorial diverges from "my goal" of
learning openGL: it starts explaining how to draw anti-aliased text or
beautiful lines, and all other things I'm not interested in...</p>

<p>The latter is a very nice comparaison (in c++) of raw OpenGL versus the Qt
"port", where Qt encapsulates -partly- OpenGL in its own classes, leading to a
more compact code. So I will also "steal" from there, but making the
comparaison in python.</p>

<p><strong><span style="color:#0000ff">In both case I will add my own comments
to the original text, for what I consider to be important!</span></strong></p>

<p></p>

<p><strong style="color:#008000">The final goal of the tutorial is to (to able
to) write a PySide6 app (or widget) simulating the milling process, given a
gcode data. The gcode may only be produced from the PyCut app, so this is very
basic gcode.</strong></p>

<p></p>

<h2 id="P-02">OpenGL Primer</h2>

<h3 id="P-02-01">The graphic pipeline</h3>

<p>If you want to understand modern OpenGL, you have to understand the graphic
pipeline and <strong>shaders</strong>. <strong>Shaders</strong> are pieces of
program (using a C-like language) that are build onto the GPU and executed
during the rendering pipeline. Depending on the nature of the shaders (there
are many types depending on the version of OpenGL you're using), they will act
at different stage of the rendering pipeline. To simplify this tutorial, we'll
use only <strong>vertex</strong> and <strong>fragment</strong>
<strong>shaders</strong> as shown below: </p>
<img src="doc_images/OpenGL_pipeline.png" width="820px" alt=""> 

<div class="info">
<strong>Note</strong> The shader language is called glsl. There are many
versions that goes from 1.0 to 1.5 and subsequent version get the number of
OpenGL version. Last version is 4.6 (June 2017).</div>

<p>A <strong>vertex shader acts on vertices</strong> and is supposed to output
the vertex position (<em>gl_Position</em>) on the viewport (i.e. screen). A
<strong>fragment shader</strong> acts at the fragment level and is supposed to
output the color (<em>gl_FragColor</em>) of the fragment. Hence, a minimal
vertex shader is: </p>
<pre style="background: #f2f2f2;"><code class="language-glsl">void main()
{
    gl_Position = vec4(0.0,0.0,0.0,1.0);
}</code></pre>
while a minimal fragment shader would be: 
<pre style="background: #f2f2f2;"><code class="language-glsl">void main()
{
    gl_FragColor = vec4(0.0,0.0,0.0,1.0);
}</code></pre>

<p>These two shaders are not very useful because the first shader will always
output the null vertex (<em>gl_Position</em> is a special variable) while the
second will only output the black color for any fragment (<em>gl_FragColor</em>
is also a special variable). We'll see later how to make them to do more useful
things.</p>

<p>One question remains: when are those shaders executed exactly ? The
<strong>vertex shader</strong> is executed for each vertex that is given to the
rendering pipeline (we'll see what does that mean exactly later) and the
<strong>fragment shader</strong> is executed on each fragment (= pixel) that is
generated after the vertex stage. For example, in the simple figure above, the
vertex would be called 3 times , once for each vertex (1,2 and 3) while the
fragment shader would be executed 21 times, once for each fragment.</p>

<h3 id="P-02-02">Buffers</h3>

<p>The next question is thus where do those vertices comes from ? The idea of
modern GL is that vertices are stored on the CPU and need to be uploaded to the
GPU before rendering. The way to do that is to <strong>build buffers onto the
CPU</strong> and to <strong>send these buffers onto the GPU</strong>. If your
data does not change, no need to upload them again. That is the big difference
with the previous fixed pipeline where data were uploaded at each rendering
call (only display lists were built into GPU memory). </p>

<p>But what is the structure of a vertex ? OpenGL does not assume anything
about your vertex structure and you're free to use as many information you may
need for each vertex. The only condition is that all vertices from a buffer
have the same structure (possibly with different content). This again is a big
difference with the fixed pipeline where OpenGL was doing a lot of complex
rendering stuff for you (projections, lighting, normals, etc.) with an implicit
fixed vertex structure. The good news is that you're now free to do anything
you want, but the bad news is that you have to program just everything. </p>

<p>Let's take a simple example of a vertex structure where we want each vertex
to hold a position and a color. The easiest way to do that in python is to use
a structured array using numpy: </p>
<pre style="background: #f2f2f2;"><code class="language-python">data = numpy.zeros(4, dtype = [ ("position", np.float32, 3),
                                ("color",    np.float32, 4)] )</code></pre>

<p>We just created a CPU buffer with 4 vertices, each of them having a position
(3 floats for x,y,z coordinates) and a color (4 floats for red, blue, green and
alpha channels). Note that we explicitly chose to have 3 coordinates for
position but we may have chosen to have only 2 if were to work in
two-dimensions. Same holds true for color. We could have used only 3 channels
(r,g,b) if we did not want to use transparency. This would save some bytes for
each vertex. Of course, for 4 vertices, this does not really matter but you
have to realize it will matter if your data size grows up to one or ten million
vertices. </p>

<h3 id="P-02-03">Variables</h3>

<p>Now, we need to explain our shaders what to do with these buffers and how to
connect them together. So, let's consider again a CPU buffer of 4 vertices
using 2 floats for position and 4 floats for color:</p>
<pre style="background: #f2f2f2;"><code class="language-python">data = numpy.zeros(4, dtype = [ ("position", np.float32, 2),
                                ("color",    np.float32, 4)] )</code></pre>

<p><strong><span style="color:#0000ff">As we send raw "buffers" to the GPU, the
shader program has no idea of the structure of the buffer (that the first 2
floats are for the position and the last 4 floats are for the color, and that
an element is made of 6 floats.</span></strong></p>

<p>We need to tell the vertex shader that it will have to handle vertices where
a position is a tuple of 2 floats and color is a tuple of 4 floats. This is
precisely what <strong>attributes</strong> are meant for. Let us change
slightly our previous vertex shader:</p>

<p><span style="color:#0000ff"><strong>We have not yet told OpenGL how to
interpret the buffer, but the attributes will help. Infact we have to tell
OpenGL from python (from where sonst) these informations</strong>.</span></p>
<pre style="background: #f2f2f2;"><code class="language-glsl">attribute vec2 position;
attribute vec4 color;
void main()
{
    gl_Position = vec4(position, 0.0, 1.0);
}</code></pre>

<p>This vertex shader now expects a vertex to possess 2 <strong><span
style="color:#ff0080">attributes</span></strong>, one named <em>position</em>
and one named <em>color</em> with specified types (vec2 means tuple of 2
floats, vec3 means tuple of 3 floats and vec4 means tuple of 4 floats). It is
important to note that even if we labeled the first attribute position,
<strong>this attribute is not yet bound to the actual position in the numpy
array</strong>. <strong><span style="color:#0000ff">We could have declared
first the color, then the position.</span></strong> We'll need to do it
explicitly at some point in our program and there is no magic that will bind
the numpy array field to the right attribute, you'll have to do it yourself,
but we'll see that later. <strong>(Yes!)</strong></p>

<p>The second type of information we can feed the vertex shader is the <strong
style="color:#ff0080">uniform</strong> that may be considered as constant value
(across all the vertices). Let's say for example we want to scale all the
vertices by a constant factor scale, we would thus write:</p>
<pre style="background: #f2f2f2;"><code class="language-glsl">uniform float scale;
attribute vec2 position;
attribute vec4 color;
void main()
{
    gl_Position = vec4(position*scale, 0.0, 1.0);
}</code></pre>

<p>Last type is the <strong style="color:#ff0080">varying</strong> type that is
used to pass information between the vertex stage and the fragment stage. So
let us suppose (again) we want to pass the vertex color to the fragment shader,
we now write: </p>
<pre style="background: #f2f2f2;"><code class="language-glsl">uniform float scale;
attribute vec2 position;
attribute vec4 color;
varying vec4 v_color;

void main()
{
    gl_Position = vec4(position*scale, 0.0, 1.0);
    v_color = color;
}</code></pre>

<p>and then in the fragment shader, we write: </p>
<pre style="background: #f2f2f2;"><code class="language-glsl">varying vec4 v_color;

void main()
{
    gl_FragColor = v_color;
}</code></pre>

<p>The question is what is the value of <em>v_color</em> inside the fragment
shader ? If you look at the figure that introduced the gl pipeline, we have 3
vertices and 21 fragments. What is the color of each individual fragment ? </p>

<p>The answer is the interpolation of all 3 vertices color. This interpolation
is made using the distance of the fragment to each individual vertex. This is a
very important concept to understand. Any varying value is interpolated between
the vertices that compose the elementary item (mostly, line or triangle). </p>

<p>Ok, enough for now, we'll see an explicit example in the next chapter. </p>

<h2 id="P-03">Preliminaries</h2>

<p>The main difficulty for newcomers in programming modern OpenGL is that it
requires to understand a lot of different concepts at once and then, to perform
a lot of operations before rendering anything on screen. This complexity
implies that there are many places where your code can be wrong, both at the
conceptual and code level. To illustrate this difficulty, we'll program our
first OpenGL program using the raw interface and our goal is to display a
simple colored quad (i.e. a red square).</p>

<h3 id="P-03-01">Normalize Device Coordinates</h3>

<p>Before even diving into actual code, it is important to understand first how
OpenGL handles coordinates. More precisely, OpenGL considers only coordinates
(x,y,z) that fall into the space where -1 ≤ x,y,z ≤ +1. Any coordinates
that are outside this range will be discarded or clipped (i.e. won't be visible
on screen). This is called Normalized Device Coordinates, or NDC for short.
This is something you cannot change because it is part of the OpenGL API and
implemented in your hardware (GPU). Consequently, even if you intend to render
the whole universe, you'll have utlimately to fit it into this small volume.</p>
<img src="doc_images/OpenGL_viewport.png" width="282px" alt=""> 

<p>The second important fact to know is that x coordinates increase from left
to right and y coordinates increase from bottom to top. For this latter one, it
is noticeably different from the usual convention and this might induce some
problems, especially when you're dealing with the mouse pointer whose y
coordinate goes the other way around.</p>

<h3 id="P-03-02">Triangulation</h3>

<p>Triangulation of a surface means to find a set of triangles, which covers a
given surface. This can be a tedious process but fortunately, there exist many
different methods and algorithms to perform such triangulation automatically
for any 2D or 3D surface. The quality of the triangulation is measured in terms
of the closeness to the approximated surface, the number of triangles necessary
(the smaller, the better) and the homogeneity of the triangles (we prefer to
have triangles that have more or less the same size and to not have any
degenerated triangle).</p>
<img src="doc_images/OpenGL_triangulations.png" width="271px" alt=""> 

<p>In our case, we want to render a square and we need to find the proper
triangulation (which is not unique as illustrated on the figure). Since we want
to minimize the number of triangles, we'll use the 2 triangles solution that
requires only 4 (shared) vertices corresponding to the four corners of the
quad. However, you can see from the figure that we could have used different
triangulations using more vertices, and later in this book we will just do that
(but for a reason).</p>

<p>Considering the NDC, our quad will thus be composed of two triangles:</p>
<ul>
  <li>One triangle described by vertices (-1,+1), (+1,+1), (-1,-1)</li>
  <li>One triangle described by vertices (+1,+1), (-1,-1), (+1,-1)</li>
</ul>

<p>Here we can see that vertices (-1,-1) and (+1,+1) are common to both
triangles. So instead of using 6 vertices to describe the two triangles, we can
re-use the common vertices to describe the whole quad. Let's name them:</p>
<ul>
  <li>V₀: (-1,+1)</li>
  <li>V₁: (+1,+1)</li>
  <li>V₂: (-1,-1)</li>
  <li>V₃: (+1,-1)</li>
</ul>

<p>Our quad can now be using triangle (V₀,V₁,V₂) and triangle
(V₁,V₂,V₃). This is exactly what we need to tell OpenGL.</p>

<h3 id="P-03-03">GL Primitives</h3>

<p>Ok, now things are getting serious because we need to actually tell OpenGL
what to do with the vertices, i.e. how to render them? What do they describe in
terms of geometrical primitives? This is quite an important topic since this
will determine how fragments will actually be generated as illustrated on the
image below:</p>
<img src="doc_images/OpenGL_primitives.png" width="315px" alt=""> 

<p>Mostly, OpenGL knows how to draw (ugly) points, (ugly) lines and (ugly)
triangles. For lines and triangles, there exist some variations depending if
you want to specify very precisely what to draw or if you can take advantage of
some implicit assumptions. Let's consider lines first for example. Given a set
of four vertices (V₀,V₁,V₂,V₃), you migh want to draw segments
(V₀,V₁)``(V₂,V₃) using GL_LINES or a broken line (V₀,V₁,V₂,V₃)
using using GL_LINE_STRIP or a closed broken line (V₀,V₁,V₂,V₃,V₀,)
using GL_LINE_LOOP. For triangles, you have the choices of specifying each
triangle individually using GL_TRIANGLES or you can tell OpenGL that triangles
follow an implicit structure using GL_TRIANGLE_STRIP. For example, considering
a set of vertices (Vᵢ), GL_TRIANGLE_STRIP will produce triangles
(Vᵢ,Vᵢ₊₁,Vᵢ₊₂). There exist other primitives but we won't used
them in this book because they're mainly related to geometry shaders that are
not introduced.</p>

<p>If you remember the previous section where we explained that our quad can be
described using using triangle (V₀,V₁,V₂) and triangle (V₁,V₂,V₃),
you can now realize that we can take advantage or the GL_TRIANGLE_STRIP
primitive because we took care of describing the two triangles following this
implicit structure.</p>

<h3 id="P-03-04">Interpolation</h3>

<p>The choice of the triangle as the only surface primitive is not an arbitrary
choice, because a triangle offers the possibility of having a nice and
intuitive interpolation of any point that is inside the triangle. If you look
back at the graphic pipeline as it has been introduced in the Modern OpenGL
section, you can see that the rasterisation requires for OpenGL to generate
fragments inside the triangle but also to interpolate values (colors on the
figure). One of the legitimate questions to be solved is then: if I have a
triangle (V₁,V₂,V₃), each summit vertex having (for example) a different
color, what is the color of a fragment p inside the triangle? The answer is
barycentric interpolation as illustrated on the figure on the right.</p>
<img src="doc_images/OpenGL_interpolation.png" width="307px" alt=""> 

<p>More precisely, for any point p inside a triangle A = (V₁,V₂,V₃), we
consider triangles:</p>
<ul>
  <li>A₁ = (P,V₂,V₃)</li>
  <li>A₂ = (P,V₁,V₃)</li>
  <li>A₃ = (P,V₁,V₂)</li>
</ul>

<p>And we can define (using area of triangles):</p>
<ul>
  <li>훌₁ = A₁/A</li>
  <li>훌₂ = A₂/A</li>
  <li>훌₃ = A₃/A</li>
</ul>

<p>Now, if we attach a value f₁ to vertex V₁, f₂ to vertex V₂ and f₃
to vertex V₃, the interpolated value f of p is given by: f = 훌₁f₁ +
훌₂f₂ + 훌₃f₃ You can check by yourself that if the point p is on a
border of the triangle, the resulting interpolated value f is the linear
interpolation of the two vertices defining the segment the point p belongs
to.</p>

<p>This barycentric interpolation is important to understand even if it is done
automatically by OpenGL (with some variation to take projection into account).
We took the example of colors, but the same interpolation scheme holds true for
any value you pass from the vertex shader to the fragment shader. And this
property will be used and abused in this book.</p>

<h2 id="P-04">Quick Start</h2>

<p>Having reviewed some important OpenGL concepts, it's time to code our quad
example. But, before even using OpenGL, we need to open a window with a valid
GL context. <strong><span style="color:#0000ff">Definition of a GL
context?</span></strong> This can be done using a toolkit such as Gtk, Qt or Wx
or any native toolkit (Windows, Linux, OSX). Unfortunately, the Tk Python
interface does not allow to create a GL context and we cannot use it. Note
there also exists dedicated toolkits such as GLFW or GLUT and the advantage of
GLUT is that it's already installed alongside OpenGL. Even if it is now
deprecated, we'll use GLUT <strong><span style="color:#0000ff">(bad luck for
python users, the GLUT python module is not easely installed)</span></strong>
since it's a very lightweight toolkit and does not require any extra package.
Here is a minimal setup that should open a window with garbage on it (since we
do not even clear the window): </p>
<pre style="background: #f2f2f2;"><code class="language-python">import sys
import OpenGL.GL as gl
import OpenGL.GLUT as glut

def display():
    glut.glutSwapBuffers()

def reshape(width,height):
    gl.glViewport(0, 0, width, height)

def keyboard( key, x, y ):
    if key == b'\x1b':
        sys.exit( )

glut.glutInit()
glut.glutInitDisplayMode(glut.GLUT_DOUBLE | glut.GLUT_RGBA)
glut.glutCreateWindow('Hello world!')
glut.glutReshapeWindow(512,512)
glut.glutReshapeFunc(reshape)
glut.glutDisplayFunc(display)
glut.glutKeyboardFunc(keyboard)
glut.glutMainLoop()</code></pre>

<p>The glutInitDisplayMode tells OpenGL what are the GL context properties. At
this stage, we only need a swap buffer (we draw on one buffer while the other
is displayed) and we use a full RGBA 32 bits color buffer (8 bits per channel).
The reshape callback informs OpenGL of the new window size while the display
method tells OpenGL what to do when a redraw is needed. In this simple case, we
just ask OpenGL to swap buffers (this avoids flickering). Finally, the keyboard
callback allows us to exit by pressing the Escape key.</p>

<h3 id="P-04-01">Writing shaders</h3>

<p>Now that your window has been created, we can start writing our program,
that is, we need to write a vertex and a fragment shader. For the vertex
shader, the code is very simple because we took care of using the normalized
device coordinates to describe our quad in the previous section. This means
vertices do not need to be transformed. Nonetheless, we have to take care of
sending 4D coordinates even though we'll transmit only 2D coordinates (x,y) or
the final result will be undefined. For coordinate z we'll just set it to 0.0
(but any value would do) and for coordinate w, we set it to 1.0 (see section
Basic Mathematics for the explanation). Note also the (commented) alternative
ways of writing the shader.</p>
<pre style="background: #f2f2f2;"><code class="language-glsl">attribute vec2 position;
void main()
{
  gl_Position = vec4(position, 0.0, 1.0);

  // or gl_Position.xyzw = vec4(position, 0.0, 1.0);

  // or gl_Position.xy = position;
  //    gl_Position.zw = vec2(0.0, 1.0);

  // or gl_Position.x = position.x;
  //    gl_Position.y = position.y;
  //    gl_Position.z = 0.0;
  //    gl_Position.w = 1.0;
}</code></pre>

<p>For the fragment shader, it is even simpler. We set the color to red which
is described by the tuple (1.0, 0.0, 0.0, 1.0) in normalized RGBA notation. 1.0
for alpha channel means fully opaque. </p>
<pre style="background: #f2f2f2;"><code class="language-glsl">void main()
{
  gl_FragColor = vec4(1.0, 0.0, 0.0, 1.0);

  // or gl_FragColor.rgba = vec4(1.0, 0.0, 0.0, 1.0);

  // or gl_FragColor.rgb = vec3(1.0, 0.0, 0.0);
  //    gl_FragColor.a = 1.0;
}</code></pre>

<h3 id="P-04-02">Compiling the program</h3>

<p>We wrote our shader and we need now to build a <strong>program</strong> that
will link the vertex and the fragment shader together. Building such program is
relatively straightforward (provided we do not check for errors). First we need
to <strong>request</strong> program and shader slots from the GPU:</p>
<pre style="background: #f2f2f2;"><code class="language-glsl">program  = gl.glCreateProgram()
vertex   = gl.glCreateShader(gl.GL_VERTEX_SHADER)
fragment = gl.glCreateShader(gl.GL_FRAGMENT_SHADER)</code></pre>

<p>We can now ask for the compilation of our shaders into GPU objects and we
log for any error from the compiler (e.g. syntax error, undefined variables,
etc):</p>
<pre style="background: #f2f2f2;"><code class="language-python">vertex_code = """
  attribute vec2 position;
  void main() { gl_Position = vec4(position, 0.0, 1.0); } """

fragment_code = """
  void main() { gl_FragColor = vec4(1.0, 0.0, 0.0, 1.0); } """

# Set shaders source
gl.glShaderSource(vertex, vertex_code)
gl.glShaderSource(fragment, fragment_code)

# Compile shaders
gl.glCompileShader(vertex)
if not gl.glGetShaderiv(vertex, gl.GL_COMPILE_STATUS):
    error = gl.glGetShaderInfoLog(vertex).decode()
    print(error)
    raise RuntimeError("Vertex shader compilation error")

gl.glCompileShader(fragment)
if not gl.glGetShaderiv(fragment, gl.GL_COMPILE_STATUS):
    error = gl.glGetShaderInfoLog(fragment).decode()
    print(error)
    raise RuntimeError("Fragment shader compilation error")</code></pre>

<p>Then we <strong>link</strong> our two objects in into a program and again,
we check for errors during the process.</p>
<pre style="background: #f2f2f2;"><code class="language-python">gl.glAttachShader(program, vertex)
gl.glAttachShader(program, fragment)
gl.glLinkProgram(program)

if not gl.glGetProgramiv(program, gl.GL_LINK_STATUS):
    print(gl.glGetProgramInfoLog(program))
    raise RuntimeError('Linking error')</code></pre>

<p>and we can get rid of the shaders, they won't be used again (you can think
of them as .o files in C).</p>
<pre style="background: #f2f2f2;"><code class="language-python">gl.glDetachShader(program, vertex)
gl.glDetachShader(program, fragment)</code></pre>

<p>Finally, we make program the default program to be ran. We can do it now
because we'll use a single program in this example <strong
style="color:#0000ff">(What if we use many programs?)</strong> :</p>
<pre style="background: #f2f2f2;"><code class="language-python">gl.glUseProgram(program)</code></pre>

<h3 id="P-04-03">Uploading data to the GPU</h3>

<p>Next, we need to build CPU data and the corresponding GPU buffer that will
hold a copy of the CPU data (GPU cannot access CPU memory). In Python, things
are grealty facilitated by NumPy that allows to have a precise control over
number representations. This is important because GLES 2.0 floats have to be
exactly 32 bits long and a regular Python float would not work (they are
actually equivalent to a C double). So let us specify a NumPy array holding
4×2 32-bits float that will correspond to our 4×(x,y) vertices:</p>
<pre style="background: #f2f2f2;"><code class="language-python"># Build data
data = np.zeros((4,2), dtype=np.float32))</code></pre>

<p>We then create a placeholder on the GPU without yet specifying the size:</p>
<pre style="background: #f2f2f2;"><code class="language-python"># Request a buffer slot from GPU
buffer = gl.glGenBuffers(1)

# Make this buffer the default one
gl.glBindBuffer(gl.GL_ARRAY_BUFFER, buffer)</code></pre>

<p>We now need to <strong>bind the buffer to the <span
style="color:#0000ff">current</span> program</strong>, that is, for each
attribute present in the vertex shader program, we need to tell OpenGL where to
find the corresponding data (i.e. GPU buffer) and this requires some
computations. More precisely, we need to tell the GPU <strong>how to read the
buffer</strong> in order to bind each value to the relevant attribute. To do
this, GPU needs to know what is the <strong>stride</strong> between 2
consecutive elements and what is the <strong>offset</strong> to read one
attribute:</p>
<img src="doc_images/OpenGL_stride1.png" width="634px" alt=""> 

<p>In our simple quad scenario, this is relatively easy to write because we
have a single attribute ("position"). <strong>We first require the attribute
location inside the program and then we bind the buffer with the relevant
offset.</strong></p>
<pre style="background: #f2f2f2;"><code class="language-python">stride = data.strides[0]

offset = ctypes.c_void_p(0)
loc = gl.glGetAttribLocation(program, "position")
gl.glEnableVertexAttribArray(loc)
gl.glBindBuffer(gl.GL_ARRAY_BUFFER, buffer)
gl.glVertexAttribPointer(loc, 2, gl.GL_FLOAT, False, stride, offset)</code></pre>

<p><strong><span style="color:#0000ff">From the shader program, we inform
python about the (opaque) location of an attribute in this program. Then we
"enable" the location, we bind the buffer, and finally give from python to the
shader program the information about the buffer stride and
offsets.</span></strong></p>

<p><strong><span style="color:#0000ff">Note that in theses lines, the numpy
array is not involved (or rather said just its layout). We just set the
structure of the "default" buffer.</span></strong></p>

<p><strong><span style="color:#0000ff">See how the last line does this, but of
course knowing that it refers to the given buffer just bound before (even if
still empty!).</span></strong></p>

<p>We're basically telling the program how to <strong>bind data to the relevant
attribute</strong>. This is made by providing the stride of the array (how many
bytes between each record) and the offset of a given attribute. </p>

<p>Let's now fill our CPU data and upload it to the newly created GPU buffer:
</p>
<pre style="background: #f2f2f2;"><code class="language-python"># Assign CPU data
data[...] = (-1,+1), (+1,+1), (-1,-1), (+1,-1)

# Upload CPU data to GPU buffer
gl.glBufferData(gl.GL_ARRAY_BUFFER, data.nbytes, data, gl.GL_DYNAMIC_DRAW)</code></pre>

<p><strong><span style="color:#0000ff">Here at the last line the shader program
nor the buffer is not specified. Hopefully we have tell OpenGL which shader
program is "active" (glUseProgram) and which is the current buffer
(glBindBuffer).</span></strong></p>

<p><span style="color:#0000ff"><strong>Question</strong></span>: what is
"GL_DYNAMIC_DRAW"?</p>

<p><span style="color:#0000ff"><strong>Remark</strong></span>: At the time of
defining the buffer, the buffer had an "unknown" size...</p>

<h3 id="P-04-04">Rendering</h3>

<p>We're done, we can now rewrite the display function:</p>
<pre style="background: #f2f2f2;"><code class="language-python">def display():
    gl.glClear(gl.GL_COLOR_BUFFER_BIT)
    gl.glDrawArrays(gl.GL_TRIANGLE_STRIP, 0, 4)
    glut.glutSwapBuffers()</code></pre>

<p>The 0,4 arguments in the glDrawArrays tells OpenGL we want to display 4
vertices from our <strong>current active buffer</strong> and we start at vertex
0. You should obtain the figure on the right with the same red (boring) color.
The whole source ia available from code/chapter-03/glut-quad-solid.py. </p>

<p><strong style="color:#0000ff">The <em>glDrawArrays</em> function does not
specify which buffer(s) is/are meant nor which program(s). Is it only be the
current buffer, or all of them, and which program (or all of them)?
</strong></p>

<p><strong style="color:#008080">Answer: <em>glDrawArrays</em> will draw from
the currently bound vertex attribute arrays, which are "created" and bound
themselves with glVertexAttribPointer and glEnableVertexAttribArray, which do
use the currently bound vertex buffer. It doesn't matter if the vertex
attributes are all from one buffer or multiple buffers, and you don't need any
particular vertex buffer to be bound when drawing; all the glDraw* functions
care about is which vertex attribute arrays are enabled.</strong></p>

<p><strong style="color:#0000ff">So see at the 3 consecutive calls
glEnableVertexAttribArray / glBindBuffer / glVertexAttribPointer above. There
can be many of then, and for all of them, the "attrib" will be
drawn.</strong></p>

<p></p>

<p>All these operations are necessary for displaying a single colored quad on
screen and complexity can escalate pretty badly if you add more objects,
projections, lighting, texture, etc. This is the reason why we'll stop using
the raw OpenGL interface in favor of a library. We'll use the glumpy library,
mostly because I wrote it, but also because it offers a tight integration with
numpy. Of course, you can design your own library to ease the writing of GL
Python applications. </p>

<h3 id="P-04-05">Uniform color</h3>

<p>In the previous example, we hard-coded the red color inside the fragment
shader source code. But what if we want to change the color from within the
Python program? We could rebuild the program with the new color but that would
not be very efficient. Fortunately there is a simple solution provided by
OpenGL: <strong><span style="color:#ff0080">uniform</span></strong>. Uniforms,
unlike attributes, do not change from one vertex to the other and this is
precisely what we need in our case. We thus need to slightly modify our
fragment shader to use this uniform color: </p>
<pre style="background: #f2f2f2;"><code class="language-glsl">uniform vec4 color;
void main()
{
  gl_FragColor = color;
}</code></pre>

<p>Of course, we also need to upload a color to this new uniform location and
this is easier than for attribute because the memory has already been allocated
on the GPU (since the size is know and does not depend on the number of
vertices).</p>
<pre style="background: #f2f2f2;"><code class="language-python">loc = gl.glGetUniformLocation(program, "color")
gl.glUniform4f(loc, 0.0, 0.0, 1.0, 1.0)</code></pre>

<p>If you run the new code/glut-quad-uniform-color.py example, you should
obtain the blue quad as shown on the right.</p>

<h3 id="P-04-06">Varying color</h3>

<p>Until now, we have been using a constant color for the four vertices of our
quad and the result is (unsurprisingly) a uniform red or blue quad. We can make
it a bit more interesting though by assigning different colors to each vertex
and see how OpenGL will interpolate colors. Our new vertex shader would need to
be rewritten as:</p>
<pre style="background: #f2f2f2;"><code class="language-glsl">attribute vec2 position;
attribute vec4 color;
varying vec4 v_color;
void main()
{
  gl_Position = vec4(position, 0.0, 1.0);
  v_color= color;
}</code></pre>

<p>We just added our new attribute <em>color</em> but we also added a new
variable type: <strong style="color:#ff0080">varying</strong>. This type is
actually used to transmit a value from the vertex shader to the fragment
shader. As you might have guessed, the varying type means this value won't be
constant over the different fragments but will be interpolated depending on the
relative position of the fragment in the triangle, as I explained in the
Interpolation section. Note that we also have to rewrite our fragment shader
accordingly, but now the <em>v_color</em> will be an input:</p>
<pre style="background: #f2f2f2;"><code class="language-glsl">varying vec4 v_color;
void main()
{
  gl_FragColor = color;
}</code></pre>

<p>We now need to upload vertex color to the GPU. <strong>We could create a new
vertex dedicated buffer and bind it to the new color attribute</strong>, but
there is a more interesting solution. We'll use instead a single numpy array
and a single buffer, taking advantage of the NumPy structured array:</p>
<pre style="background: #f2f2f2;"><code class="language-python">data = np.zeros(4, [("position", np.float32, 2),
                    ("color",    np.float32, 4)])
data['position'] = (-1,+1), (+1,+1), (-1,-1), (+1,-1)
data['color']    = (0,1,0,1), (1,1,0,1), (1,0,0,1), (0,0,1,1)</code></pre>

<p>Our CPU data structure is thus:</p>
<img src="doc_images/OpenGL_stride2.png" width="726px" alt=""> 

<p>Binding the buffer is now a bit more complicated but it is made relatively
easy thanks to NumPy:</p>
<pre style="background: #f2f2f2;"><code class="language-python">stride = data.strides[0]
offset = ctypes.c_void_p(0)
loc = gl.glGetAttribLocation(program, "position")
gl.glEnableVertexAttribArray(loc)
gl.glBindBuffer(gl.GL_ARRAY_BUFFER, buffer)
gl.glVertexAttribPointer(loc, 2, gl.GL_FLOAT, False, stride, offset)

offset = ctypes.c_void_p(data.dtype["position"].itemsize)
loc = gl.glGetAttribLocation(program, "color")
gl.glEnableVertexAttribArray(loc)
gl.glBindBuffer(gl.GL_ARRAY_BUFFER, buffer)
gl.glVertexAttribPointer(loc, 4, gl.GL_FLOAT, False, stride, offset)</code></pre>

<p><strong style="color:#0000ff">Unfortunately, the case where there are 2
buffers for one program is not covered (as well as many buffers with many
programs) as these cases are equally interesting, or even more, as this is the
case when the application grows in complexity.</strong></p>

<p><strong style="color:#008040">As stated above in the Question/Answer, keys
are the <em>glEnableVertexAttribArray</em> and <em>glVertexAttribPointer</em>.
To enable them, a <em>glBindBuffer</em> between the 2 calls is neccessary,
especially if the arrays are from different buffers. But at the end, not the
buffers are relevant, but the
<em>VertexAttribArrays</em>/<em>VertexAttribPointer</em>.</strong></p>

<p>We now translate Mr. Rougier examples so that they work with PySide. They
become thus more lines of code, but without the glumpy magic.</p>

<h2 id="P-05">PySide6 and OpenGL</h2>

<p>I have tried to make the code as short as possible without sacrifying the
readability</p>

<h3 id="P-05-01" class="accordion">A blue quad</h3>

<div class="panel">
<pre style="background: #f2f2f2;"><code class="language-python">
import ctypes
import sys
from typing import List
  
import numpy as np

from PySide6.QtCore import Qt, QSize, QPointF
from PySide6.QtGui import (QOpenGLFunctions, QVector2D)
from PySide6.QtWidgets import (QApplication, QMainWindow)

from PySide6.QtOpenGL import (QOpenGLVertexArrayObject, QOpenGLBuffer, QOpenGLShaderProgram, QOpenGLShader)
from PySide6.QtOpenGLWidgets import QOpenGLWidget
  
from OpenGL import GL
  
  
class Window(QMainWindow):
    def __init__(self, parent=None):
        QMainWindow.__init__(self, parent)

        self.gl_widget = GLWidget()

        self.setCentralWidget(self.gl_widget)
        self.setWindowTitle(self.tr("Hello GL"))

class Vertex:
    nb_float = 2
    bytes_size = nb_float * 4 #  4 bytes each
    # the size/offset do not strictly belong to the Vertex class, but are properties
    # of the generated numpy array. However it is pratical to have them here. 
    size = {'position' : 2 } # size in float of position
    offset = {'position' : 0 } # offsets in np array

    def __init__(self, position):
        self.position = position

    @classmethod
    def toNumpyArray(cls, vertices: List['Vertex']) -&gt; np.ndarray:
        # fill the numpy array - each vertex is composed of 2 float
        np_array = np.empty(len(vertices) * cls.nb_float, dtype=ctypes.c_float)
    
        for k, vertex in enumerate(vertices):
            np_array[2*k + 0] = vertex.position.x()
            np_array[2*k + 1] = vertex.position.y()
    
        return np_array

class Scene():
    def __init__(self):
        self.nb_vertex = 6
        self.nb_float = self.nb_vertex * Vertex.nb_float
        
        vertices : List[Vertex] = []
        
        # define vertices - first triangle
        vertices.append( Vertex(QVector2D(-1,-1)) )
        vertices.append( Vertex(QVector2D(1,1)) )
        vertices.append( Vertex(QVector2D(-1,1)) )

        # define vertices - second triangle
        vertices.append( Vertex(QVector2D(1,1)) )
        vertices.append( Vertex(QVector2D(-1,-1)) )
        vertices.append( Vertex(QVector2D(1,-1)) )
        
        # fill the numpy array
        self.m_data = Vertex.toNumpyArray(vertices)
        
    def const_data(self):
        return self.m_data.tobytes()

class GLWidget(QOpenGLWidget, QOpenGLFunctions):
    vertex_code = """
    attribute vec2 position;
    void main(){ gl_Position = vec4(position, 0.0, 1.0); } """
    
    fragment_code = """
    uniform vec4 color;
    void main() { gl_FragColor = color; } """
    
    def __init__(self, parent=None):
        QOpenGLWidget.__init__(self, parent)
        QOpenGLFunctions.__init__(self)
    
        self.scene = Scene()
        self.vao = QOpenGLVertexArrayObject()
        self._scene_vbo = QOpenGLBuffer()
        self.program = QOpenGLShaderProgram()

    def cleanup(self):
        self.makeCurrent()
        self.vbo.destroy()
        del self.program
        self.program = None
        self.doneCurrent()

    def initializeGL(self):
        self.context().aboutToBeDestroyed.connect(self.cleanup)
        self.initializeOpenGLFunctions()
        self.glClearColor(0, 0, 0, 0)

        self.program = QOpenGLShaderProgram()

        self.program.addShaderFromSourceCode(QOpenGLShader.Vertex, self.vertex_code)
        self.program.addShaderFromSourceCode(QOpenGLShader.Fragment, self.fragment_code)
        self.program.link()

        self.program.bind()

        self.vao.create()
        vao_binder = QOpenGLVertexArrayObject.Binder(self.vao)

        self.vbo.create()
        self.vbo.bind()
        self.vbo.allocate(self.scene.const_data(), self.scene.nb_float * self.float_size)

        self.setup_vertex_attribs()

        self.program.release()
        vao_binder = None

    def setup_vertex_attribs(self):
        self.vbo.bind()

        # the uniform stuff
        colorLocation = self.program.uniformLocation("color")
        self.program.setUniformValue(colorLocation, 0.0, 0.0, 1.0, 1.0)

        # Offset for position
        offset = Vertex.offset['position']
        size = Vertex.size['position'] # nb float in a position "packet" 
        stride = Vertex.bytes_size # nb bytes in a Vertex 

        vertexLocation = self.program.attributeLocation("position")
        self.program.enableAttributeArray(vertexLocation)
        self.program.setAttributeBuffer(vertexLocation, GL.GL_FLOAT, offset, size, stride)

        self.vbo.release()

    def paintGL(self):
        self.glClear(GL.GL_COLOR_BUFFER_BIT | GL.GL_DEPTH_BUFFER_BIT)
        self.glEnable(GL.GL_DEPTH_TEST)
       
        vao_binder = QOpenGLVertexArrayObject.Binder(self.vao)
        self.program.bind()
        self.glDrawArrays(GL.GL_TRIANGLES, 0, self.scene.nb_vertex)
        self.program.release()
        vao_binder = None

    def resizeGL(self, width, height):
        pass

if __name__ == '__main__':
    app = QApplication(sys.argv)

    main_window = Window()
    main_window.show()

    res = app.exec()
    sys.exit(res)</code></pre>
</div>

<p>In this first basic example, a <strong>Vertex</strong> class is defined (as
in all further examples) to hold the properties of the vertices. In this case,
only the position x and y of the vertices.</p>

<p>The <strong>Vertex</strong> class also contains the method to generate a
numpy array from a list of vertices, while the <strong>Scene</strong> class
creates itself the list of vertices. Here there are only 2 triangles and 6
vertices.</p>

<h3 id="P-05-02" class="accordion">A colored quad</h3>

<div class="panel">
<pre style="background: #f2f2f2;"><code class="language-python">...

class Vertex:
    nb_float = 6
    bytes_size = nb_float * 4 #  4 bytes each
    # the size/offset do not strictly belong to the Vertex class, but are properties
    # of the generated numpy array. However it is pratical to have them here.
    size = {'position' : 2 , 'color': 4} # size in float of position/color
    offset = {'position' : 0, 'color': 8 } # offsets in np array in bytes

    def __init__(self, position: QVector2D, color: QVector4D):
        self.position = position
        self.color = color

    @classmethod
    def toNumpyArray(cls, vertices: List['Vertex']) -&gt; np.ndarray:
        # fill the numpy array - each vertex is composed of 6 float
        np_array = np.empty(len(vertices) * cls.nb_float, dtype=ctypes.c_float)

        for k, vertex in enumerate(vertices):
            np_array[6*k + 0] = vertex.position.x()
            np_array[6*k + 1] = vertex.position.y()
            np_array[6*k + 2] = vertex.color.x()
            np_array[6*k + 3] = vertex.color.y()
            np_array[6*k + 4] = vertex.color.z()
            np_array[6*k + 5] = vertex.color.w()

        return np_array

class Scene():
    def __init__(self):
        self.nb_vertex = 6
        self.nb_float = self.nb_vertex * Vertex.nb_float

        vertices : List[Vertex] = []

        # collect vertices - first triangle
        vertices.append( Vertex(QVector2D(-1,-1),  QVector4D(0,0,1,1)) )
        vertices.append( Vertex(QVector2D(1,1), QVector4D(1,0,0,1)) )
        vertices.append( Vertex(QVector2D(-1,1), QVector4D(1,1,0,1)) )
        # collect vertices - second triangle
        vertices.append( Vertex(QVector2D(1,1), QVector4D(1,0,0,1)) )
        vertices.append( Vertex(QVector2D(-1,-1), QVector4D(0,0,1,1)) )
        vertices.append( Vertex(QVector2D(1,-1), QVector4D(0,1,0,1) ) )

        # fill the numpy array
        self.m_data = Vertex.toNumpyArray(vertices)

    def const_data(self):
        return self.m_data.tobytes()

class GLWidget(QOpenGLWidget, QOpenGLFunctions):
    vertex_code = """
    attribute vec2 position;
    attribute vec4 color;
    varying vec4 v_color;
    void main()
    {
        gl_Position = vec4(position, 0.0, 1.0);
        v_color= color;
    } """

    fragment_code = """
    varying vec4 v_color;
    void main() { gl_FragColor = v_color; } """

    ...

    def setup_vertex_attribs(self):
        self.vbo.bind()

        # Offset for position
        offset = Vertex.offset['position']
        size = Vertex.size['position'] # nb float in a position "packet" 
        stride = Vertex.bytes_size # nb bytes in a vertex

        vertexLocation = self.program.attributeLocation("position")
        self.program.enableAttributeArray(vertexLocation)
        self.program.setAttributeBuffer(vertexLocation, GL.GL_FLOAT, offset, size, stride)

        # Offset for color
        offset = Vertex.offset['color'] # size of preceding data (position = QVector2D)
        size = Vertex.size['color'] # nb float in a color "packet"
        stride = Vertex.bytes_size # nb bytes in a vertex 

        colorLocation =  self.program.attributeLocation("color")
        self.program.enableAttributeArray(colorLocation)
        self.program.setAttributeBuffer(colorLocation, GL.GL_FLOAT, offset, size, stride)

        self.vbo.release()
    ...</code></pre>
</div>

<p>This time, the color of the vertices is also packed in the
<strong>Vertex</strong> data, so the <strong>Vertex</strong> definition is more
interessant.</p>

<p>Note how the properties of the <strong>Vertex</strong> class (stride,
offsets, positions) are used in the OpenGL widget
<strong>"setup_vertex_attribs"</strong> method to correctly setup the
<strong>shader program</strong>.</p>

<p>The <strong>Scene</strong> properties <strong>nb_float<strong>and
</strong>nb_vertex</strong> are also used, the first one in
<strong>"setup_vertex_attribs"</strong>, the second one in the openGL function
:</p>
<pre style="background: #ffffff;"><code class="language-python">self.glDrawArrays(GL.GL_TRIANGLES, 0, self.scene.nb_vertex)</code></pre>

<h3 id="P-05-03" class="accordion">A colored quad - animated</h3>

<div class="panel">
<pre style="background: #f2f2f2;"><code class="language-python">...
class GLWidget(QOpenGLWidget, QOpenGLFunctions):
    vertex_code = """
    //uniform float scale;  // sending an uniform float is buggy in PySide-6.2!!!
    uniform vec2 scale;
    attribute vec2 position;
    attribute vec4 color;
    varying vec4 v_color;

    void main()
    {
        gl_Position = vec4(scale[0] * position, 0.0, 1.0);
        v_color = color;
    } """

    fragment_code = """
    varying vec4 v_color;
    void main() { gl_FragColor = v_color; } """
  
    float_size = ctypes.sizeof(ctypes.c_float) # 4 bytes

    def __init__(self, parent=None):
        QOpenGLWidget.__init__(self, parent)
        QOpenGLFunctions.__init__(self)

        self.scene = Scene()
        self.vao = QOpenGLVertexArrayObject()
        self.vbo = QOpenGLBuffer()
        self.program = QOpenGLShaderProgram()

        # timer stuff for animation
        self.timer = 0
        self.scale = 0.5

        id = self.startTimer(0.5)
    ...

    def setup_vertex_attribs(self):
        self.vbo.bind()

        # the uniform scale
        scaleLocation = self.program.uniformLocation("scale")
        self.program.setUniformValue(scaleLocation, self.scale, 0.0)
        ...


    def paintGL(self):
        self.glClear(GL.GL_COLOR_BUFFER_BIT | GL.GL_DEPTH_BUFFER_BIT)
        self.glEnable(GL.GL_DEPTH_TEST)
       
        vao_binder = QOpenGLVertexArrayObject.Binder(self.vao)
        self.program.bind()
        
        # inside the paintGL, we update the scale in the buffer
        scaleLocation = self.program.uniformLocation("scale")
        self.program.setUniformValue(scaleLocation, self.scale, 0.0)

        self.glDrawArrays(GL.GL_TRIANGLES, 0, self.scene.nb_vertex)
        self.program.release()
        vao_binder = None

    def timerEvent(self, event):
        self.timer += 0.25 * math.pi/180.0
        self.scale = math.cos(self.timer)

        self.update()</code></pre>
</div>

<p>We further expand the <strong>Vertex</strong> class with a scale factor, so
the <strong>setup_vertex_attribs</strong> method is also updated.</p>

<p>The programmer has only to care of not mixing
<strong>uniformLocation</strong> with <strong>attributeLocation</strong>
function calls for the respective shaders variables</p>

<h3 id="P-05-04" class="accordion">A cube</h3>

<div class="panel">
<pre style="background: #f2f2f2;"><code class="language-python">...
    
class Vertex:
    nb_float = 7
    bytes_size = nb_float * 4 #  4 bytes each
    # the size/offset do not strictly belong to the Vertex class, but are properties
    # of the generated numpy array. However it is pratical to have them here.
    size = {'position' : 3 , 'color': 4} # size in float of position/color
    offset = {'position' : 0, 'color': 12 } # offsets in np array in bytes

    def __init__(self, position: QVector3D, color: QVector4D):
        self.position = position
        self.color = color

    @classmethod
    def toNumpyArray(cls, vertices: List['Vertex']) -&gt; np.ndarray:
        np_array = np.empty(len(vertices) * cls.nb_float, dtype=ctypes.c_float)

        for k, vertex in enumerate(vertices):
            np_array[7*k + 0] = vertex.position.x()
            np_array[7*k + 1] = vertex.position.y()
            np_array[7*k + 2] = vertex.position.z()
            np_array[7*k + 3] = vertex.color.x()
            np_array[7*k + 4] = vertex.color.y()
            np_array[7*k + 5] = vertex.color.z()
            np_array[7*k + 6] = vertex.color.w()

        return np_array


class Scene():
    '''
    A cube 
    '''
    def __init__(self):
        self.nb_vertex = 8
        self.nb_float = self.nb_vertex * Vertex.nb_float

        self.nb_triangles = 12
        self.nb_int = self.nb_triangles * 3

        # 8 vertices -&gt; VertexBuffer
        vertices : List[Vertex] = []

        vertices.append( Vertex(QVector3D( 1, 1, 1), QVector4D(0,1,1,1)) )
        vertices.append( Vertex(QVector3D(-1, 1, 1), QVector4D(0,0,1,1)) )
        vertices.append( Vertex(QVector3D(-1,-1, 1), QVector4D(0,0,0,1)) )
        vertices.append( Vertex(QVector3D( 1,-1, 1), QVector4D(0,1,0,1)) )
        vertices.append( Vertex(QVector3D( 1,-1,-1), QVector4D(1,1,0,1)) )
        vertices.append( Vertex(QVector3D( 1, 1,-1), QVector4D(1,1,1,1)) )
        vertices.append( Vertex(QVector3D(-1, 1,-1), QVector4D(1,0,1,1)) )
        vertices.append( Vertex(QVector3D(-1,-1,-1), QVector4D(1,0,0,1)) )

        # fill the numpy array
        self.m_data = Vertex.toNumpyArray(vertices)

        # shared by 12 triangles -&gt; IndexBuffer
        self.i_data = np.array([
                0,1,2, 
                0,2,3,  
                0,3,4, 
                0,4,5,  
                0,5,6, 
                0,6,1,
                1,6,7, 
                1,7,2,  
                7,4,3, 
                7,3,2,  
                4,7,6, 
                4,6,5], dtype=np.uint32)


    def const_vertex_data(self):
        return self.m_data.tobytes()

    def const_index_data(self):
        return self.i_data.tobytes()


class GLWidget(QOpenGLWidget, QOpenGLFunctions):
    vertex_code = """
    uniform mat4   model;
    uniform mat4   view;
    uniform mat4   projection;
    attribute vec3 position;
    attribute vec4 color;
    varying vec4   v_color;

    void main()
    {
        gl_Position = projection * view * model * vec4(position, 1.0);

        v_color = color;
    }  """

    fragment_code = """
    varying vec4 v_color;
    void main() { gl_FragColor = v_color; } """

    float_size = ctypes.sizeof(ctypes.c_float) # 4 bytes
    int_size = ctypes.sizeof(ctypes.c_uint32) # 4 bytes

    def __init__(self, parent=None):
        QOpenGLWidget.__init__(self, parent)
        QOpenGLFunctions.__init__(self)

        self.scene = Scene()
        self.vao = QOpenGLVertexArrayObject()
        self.vbo = QOpenGLBuffer()
        self.ibo = QOpenGLBuffer()
        self.program = QOpenGLShaderProgram()

        self.proj = QMatrix4x4()
        self.proj.setToIdentity()
        self.view = QMatrix4x4()
        self.view.setToIdentity()
        self.view.translate(QVector3D(0,0,-5))
        self.model = QMatrix4x4()
        self.model.setToIdentity()

        self.theta = 0.0 # degrees
        self.phi = 0.0 # degrees

        self.timer = 0

        id = self.startTimer(1) 

    def sizeHint(self):
        return QSize(400, 400)

    def cleanup(self):
        self.makeCurrent()
        self.vbo.destroy()
        del self.program
        self.program = None
        self.doneCurrent()

    def initializeGL(self):
        self.context().aboutToBeDestroyed.connect(self.cleanup)
        self.initializeOpenGLFunctions()
        self.glClearColor(0, 0, 0, 0)

        self.program = QOpenGLShaderProgram()

        self.program.addShaderFromSourceCode(QOpenGLShader.Vertex, self.vertex_code)
        self.program.addShaderFromSourceCode(QOpenGLShader.Fragment, self.fragment_code)
        self.program.link()

        self.program.bind()

        self.vao.create()
        vao_binder = QOpenGLVertexArrayObject.Binder(self.vao)

        self.vbo.create() # QOpenGLBuffer.VertexBuffer
        self.vbo.bind()
        self.vbo.allocate(self.scene.const_vertex_data(), self.scene.nb_float * self.float_size)

        self.ibo.create() # QOpenGLBuffer.IndexBuffer
        self.ibo.bind()
        self.ibo.allocate(self.scene.const_index_data(), self.scene.nb_int * self.int_size)

        self.setup_vertex_attribs()

        self.program.release()
        vao_binder = None

    def setup_vertex_attribs(self):
        self.vbo.bind()

        modelLocation = self.program.uniformLocation("model")
        self.program.setUniformValue(modelLocation, self.model)

        projLocation = self.program.uniformLocation("projection")
        self.program.setUniformValue(projLocation, self.proj)

        viewLocation = self.program.uniformLocation("view")
        self.program.setUniformValue(viewLocation, self.view)

        # Offset for position
        offset = Vertex.offset['position']
        size = Vertex.size['position'] # nb float in a position "packet" 
        stride = Vertex.bytes_size # nb bytes in a vertex "packet" 

        vertexLocation = self.program.attributeLocation("position")
        self.program.enableAttributeArray(vertexLocation)
        self.program.setAttributeBuffer(vertexLocation, GL.GL_FLOAT, offset, size, stride)

        # Offset for color
        offset = Vertex.offset['color'] # size in bytes of preceding data (position = QVector3D)
        size = Vertex.size['color'] # nb float in a color "packet" 
        stride = Vertex.bytes_size # nb bytes in a vertex "packet" 

        colorLocation =  self.program.attributeLocation("color")
        self.program.enableAttributeArray(colorLocation)
        self.program.setAttributeBuffer(colorLocation, GL.GL_FLOAT, offset, size, stride)

        self.vbo.release()

    def paintGL(self):
        self.glClear(GL.GL_COLOR_BUFFER_BIT | GL.GL_DEPTH_BUFFER_BIT)
        self.glEnable(GL.GL_DEPTH_TEST)
       
        vao_binder = QOpenGLVertexArrayObject.Binder(self.vao)
        self.program.bind()
        
        modelLocation = self.program.uniformLocation("model")
        self.program.setUniformValue(modelLocation, self.model)

        projLocation = self.program.uniformLocation("projection")
        self.program.setUniformValue(projLocation, self.proj)

        viewLocation = self.program.uniformLocation("view")
        self.program.setUniformValue(viewLocation, self.view)

        # Filled cube
        self.glDrawElements(GL.GL_TRIANGLES, 12*3, GL.GL_UNSIGNED_INT, self.scene.const_index_data())

        self.program.release()
        vao_binder = None

    def resizeGL(self, width, height):
        ratio = width / float(height)
        self.proj.perspective(45.0, ratio, 2.0, 100.0)

    def timerEvent(self, event):
        self.timer += 0.25 * math.pi/180.0
        
        # Make cube rotate
        self.theta += 1.0 # degrees
        self.phi += 1.0 # degrees
        
        self.model = QMatrix4x4()
        self.model.setToIdentity()
        self.model.rotate(self.theta, 0, 0, 1)
        self.model.rotate(self.phi, 0, 1, 0)
        
        self.update()
</code></pre>
</div>

<p>The full cube demo is 270 lines long</p>

<p>This times, vertices are shared between the triangles, so we do not use
anymore the <strong>glDrawArrays</strong>, but instead the
<strong><code>glDrawElements</code></strong> method together with an
<strong>indexBuffer</strong>.</p>

<p>Please inspect the code carefully and check that the 8 vertices define the
12 triangles.</p>

<p>The GLWidget defines 2 buffers, the vertex buffer and the index buffer</p>

<h3 id="P-05-05" class="accordion">A cube with outlined edges</h3>

<div class="panel">
<pre style="background: #f2f2f2;"><code class="language-python">

import ctypes
import math
import numpy as np
import sys
from typing import List

from PySide6.QtCore import QSize
from PySide6.QtGui import (QOpenGLFunctions, QVector3D, QVector4D, QMatrix4x4)
from PySide6.QtWidgets import (QApplication, QMainWindow)

from PySide6.QtOpenGL import (QOpenGLVertexArrayObject, QOpenGLBuffer, QOpenGLShaderProgram, QOpenGLShader)
from PySide6.QtOpenGLWidgets import QOpenGLWidget

from OpenGL import GL


class Window(QMainWindow):
    def __init__(self, parent=None):
        QMainWindow.__init__(self, parent)

        self.gl_widget = GLWidget()

        self.setCentralWidget(self.gl_widget)
        self.setWindowTitle(self.tr("Hello GL"))

class Vertex:
    nb_float = 7
    bytes_size = nb_float * 4 #  4 bytes each
    # the size/offset do not strictly belong to the Vertex class, but are properties
    # of the generated numpy array. However it is pratical to have them here.
    size = {'position' : 3 , 'color': 4} # size in float of position/color
    offset = {'position' : 0, 'color': 12 } # offsets in np array in bytes

    def __init__(self, position: QVector3D, color: QVector4D):
        self.position = position
        self.color = color

    @classmethod
    def toNumpyArray(cls, vertices: List['Vertex']) -&gt; np.ndarray:
        np_array = np.empty(len(vertices) * cls.nb_float, dtype=ctypes.c_float)

        for k, vertex in enumerate(vertices):
            np_array[7*k + 0] = vertex.position.x()
            np_array[7*k + 1] = vertex.position.y()
            np_array[7*k + 2] = vertex.position.z()
            np_array[7*k + 3] = vertex.color.x()
            np_array[7*k + 4] = vertex.color.y()
            np_array[7*k + 5] = vertex.color.z()
            np_array[7*k + 6] = vertex.color.w()

        return np_array


class Scene():
    '''
    A cube 
    '''
    def __init__(self):
        self.nb_vertex = 8
        self.nb_float = self.nb_vertex * Vertex.nb_float

        self.nb_triangles = 12
        self.nb_int_tri = self.nb_triangles * 3

        self.nb_edges = 12
        self.nb_int_edge = self.nb_edges * 2
                   
        # 8 vertices -&gt; VertexBuffer
        vertices : List[Vertex] = []

        vertices.append( Vertex(QVector3D( 1, 1, 1), QVector4D(0,1,1,1)) )
        vertices.append( Vertex(QVector3D(-1, 1, 1), QVector4D(0,0,1,1)) )
        vertices.append( Vertex(QVector3D(-1,-1, 1), QVector4D(0,0,0,1)) )
        vertices.append( Vertex(QVector3D( 1,-1, 1), QVector4D(0,1,0,1)) )
        vertices.append( Vertex(QVector3D( 1,-1,-1), QVector4D(1,1,0,1)) )
        vertices.append( Vertex(QVector3D( 1, 1,-1), QVector4D(1,1,1,1)) )
        vertices.append( Vertex(QVector3D(-1, 1,-1), QVector4D(1,0,1,1)) )
        vertices.append( Vertex(QVector3D(-1,-1,-1), QVector4D(1,0,0,1)) )

        # fill the numpy array
        self.m_data = Vertex.toNumpyArray(vertices)

        # shared by 12 triangles -&gt; IndexBuffer
        self.i_data = np.array([
                0,1,2, 
                0,2,3,  
                0,3,4, 
                0,4,5,  
                0,5,6, 
                0,6,1,
                1,6,7, 
                1,7,2,  
                7,4,3, 
                7,3,2,  
                4,7,6, 
                4,6,5], dtype=np.uint32)

        # an other index buffer to draw lines on the edges # 24 int
        self.edge_data = np.array([
            0,1, 1,2, 2,3, 3,0,
            4,7, 7,6, 6,5, 5,4,
            0,5, 1,6, 2,7, 3,4 ])


    def const_vertex_data(self):
        return self.m_data.tobytes()

    def const_index_data(self):
        return self.i_data.tobytes()

    def const_edge_data(self):
        return self.edge_data.tobytes()


class GLWidget(QOpenGLWidget, QOpenGLFunctions):
    vertex_code = """
    uniform vec4   g_color;       // Global color
    uniform mat4   model;
    uniform mat4   view;
    uniform mat4   projection;
    attribute vec3 position;
    attribute vec4 color;
    varying vec4   v_color;

    void main()
    {
        gl_Position = projection * view * model * vec4(position, 1.0);

        v_color = g_color * color;
    }  """

    fragment_code = """
    varying vec4 v_color;
    void main() { gl_FragColor = v_color; } """

    float_size = ctypes.sizeof(ctypes.c_float) # 4 bytes
    int_size = ctypes.sizeof(ctypes.c_uint32) # 4 bytes

    def __init__(self, parent=None):
        QOpenGLWidget.__init__(self, parent)
        QOpenGLFunctions.__init__(self)

        self.scene = Scene()
        self.vao = QOpenGLVertexArrayObject()
        self.vbo = QOpenGLBuffer()
        self.ibo = QOpenGLBuffer()
        self.ebo = QOpenGLBuffer()
        self.program = QOpenGLShaderProgram()

        self.proj = QMatrix4x4()
        self.proj.setToIdentity()
        self.view = QMatrix4x4()
        self.view.setToIdentity()
        self.view.translate(QVector3D(0,0,-5))
        self.model = QMatrix4x4()
        self.model.setToIdentity()

        self.theta = 0.0 # degrees
        self.phi = 0.0 # degrees

        self.timer = 0

        id = self.startTimer(1) 

    def sizeHint(self):
        return QSize(400, 400)

    def cleanup(self):
        self.makeCurrent()
        self.vbo.destroy()
        del self.program
        self.program = None
        self.doneCurrent()

    def initializeGL(self):
        self.context().aboutToBeDestroyed.connect(self.cleanup)
        self.initializeOpenGLFunctions()
        self.glClearColor(0, 0, 0, 0)

        self.program = QOpenGLShaderProgram()

        self.program.addShaderFromSourceCode(QOpenGLShader.Vertex, self.vertex_code)
        self.program.addShaderFromSourceCode(QOpenGLShader.Fragment, self.fragment_code)
        self.program.link()

        self.program.bind()

        self.vao.create()
        vao_binder = QOpenGLVertexArrayObject.Binder(self.vao)

        self.vbo.create() # QOpenGLBuffer.VertexBuffer
        self.vbo.bind()
        self.vbo.allocate(self.scene.const_vertex_data(), self.scene.nb_float * self.float_size)

        self.ibo.create() # QOpenGLBuffer.IndexBuffer
        self.ibo.bind()
        self.ibo.allocate(self.scene.const_index_data(), self.scene.nb_int_tri * self.int_size)

        self.ebo.create() # QOpenGLBuffer.IndexBuffer
        self.ebo.bind()
        self.ebo.allocate(self.scene.const_edge_data(), self.scene.nb_int_edge * self.int_size)


        self.setup_vertex_attribs()

        self.program.release()
        vao_binder = None

    def setup_vertex_attribs(self):
        self.vbo.bind()

        gcolorLocation = self.program.uniformLocation("g_color")
        self.program.setUniformValue(gcolorLocation, QVector4D(1,1,1,1))

        modelLocation = self.program.uniformLocation("model")
        self.program.setUniformValue(modelLocation, self.model)

        projLocation = self.program.uniformLocation("projection")
        self.program.setUniformValue(projLocation, self.proj)

        viewLocation = self.program.uniformLocation("view")
        self.program.setUniformValue(viewLocation, self.view)

        # Offset for position
        offset = Vertex.offset['position']
        size = Vertex.size['position'] # nb float in a position "packet" 
        stride = Vertex.bytes_size # nb bytes in a vertex "packet" 

        vertexLocation = self.program.attributeLocation("position")
        self.program.enableAttributeArray(vertexLocation)
        self.program.setAttributeBuffer(vertexLocation, GL.GL_FLOAT, offset, size, stride)

        # Offset for color
        offset = Vertex.offset['color'] # size in bytes of preceding data (position = QVector3D)
        size = Vertex.size['color'] # nb float in a color "packet" 
        stride = Vertex.bytes_size # nb bytes in a vertex "packet" 

        colorLocation =  self.program.attributeLocation("color")
        self.program.enableAttributeArray(colorLocation)
        self.program.setAttributeBuffer(colorLocation, GL.GL_FLOAT, offset, size, stride)

        self.vbo.release()

    def paintGL(self):
        self.glClear(GL.GL_COLOR_BUFFER_BIT | GL.GL_DEPTH_BUFFER_BIT)
        self.glDisable(GL.GL_BLEND)
        self.glEnable(GL.GL_DEPTH_TEST)
        self.glEnable(GL.GL_POLYGON_OFFSET_FILL)
       
        vao_binder = QOpenGLVertexArrayObject.Binder(self.vao)
        self.program.bind()
        
        gcolorLocation = self.program.uniformLocation("g_color")
        self.program.setUniformValue(gcolorLocation, QVector4D(1,1,1,1))

        modelLocation = self.program.uniformLocation("model")
        self.program.setUniformValue(modelLocation, self.model)

        projLocation = self.program.uniformLocation("projection")
        self.program.setUniformValue(projLocation, self.proj)

        viewLocation = self.program.uniformLocation("view")
        self.program.setUniformValue(viewLocation, self.view)

        # Filled cube
        self.glDrawElements(GL.GL_TRIANGLES, 12*3, GL.GL_UNSIGNED_INT, self.scene.const_index_data())

        # Outlined cube
        self.glDisable(GL.GL_POLYGON_OFFSET_FILL)
        self.glEnable(GL.GL_BLEND)
        self.glDepthMask(GL.GL_FALSE)

        gcolorLocation = self.program.uniformLocation("g_color")
        self.program.setUniformValue(gcolorLocation, QVector4D(0, 0, 0, 1))

        self.glDrawElements(GL.GL_LINES, 12*2, GL.GL_UNSIGNED_INT, self.scene.const_edge_data())
        self.glDepthMask(GL.GL_TRUE)

        self.program.release()
        vao_binder = None

    def resizeGL(self, width, height):
        ratio = width / float(height)
        self.proj.perspective(45.0, ratio, 2.0, 100.0)

    def timerEvent(self, event):
        self.timer += 0.25 * math.pi/180.0
        
        # Make cube rotate
        self.theta += 1.0 # degrees
        self.phi += 1.0 # degrees
        
        self.model = QMatrix4x4()
        self.model.setToIdentity()
        self.model.rotate(self.theta, 0, 0, 1)
        self.model.rotate(self.phi, 0, 1, 0)
        
        self.update()


if __name__ == '__main__':
    app = QApplication(sys.argv)

    main_window = Window()
    main_window.show()

    res = app.exec()
    sys.exit(res)</code></pre>
</div>

<p>A small increment from the cube demo. We define 2 index buffers, the second
one used to draw lines on the cube.</p>

<p>So there are 2 calls to the <strong><code>self.glDrawArrays</code></strong>
method. See how in the <strong><code>paintGL</code></strong> method we can make
calls to the shader program methods, this time </p>
<pre style="background: #f2f2f2;"><code class="language-python">self.program.setUniformValue(gcolorLocation, QVector4D(0, 0, 0, 1))</code></pre>

<p>in order to draw the line black.</p>

<h3 id="P-05-06" class="accordion">A cube with texture</h3>

<div class="panel">
<pre style="background: #f2f2f2;"><code class="language-python">
import ctypes
import math
import numpy as np
import sys
  
from PySide6.QtCore import QSize
from PySide6.QtGui import (QOpenGLFunctions, QVector2D, QVector3D, QVector4D, QMatrix4x4, QImage)
from PySide6.QtWidgets import (QApplication, QMainWindow)
  
from PySide6.QtOpenGL import (QOpenGLVertexArrayObject, QOpenGLBuffer, QOpenGLShaderProgram, QOpenGLShader, QOpenGLTexture)
from PySide6.QtOpenGLWidgets import QOpenGLWidget
  
from OpenGL import GL
  
  
class Window(QMainWindow):
    def __init__(self, parent=None):
        QMainWindow.__init__(self, parent)

        self.gl_widget = GLWidget()
  
        self.setCentralWidget(self.gl_widget)
        self.setWindowTitle(self.tr("Hello GL"))
  
class Vertex:
    nb_float = 9
    bytes_size = nb_float * 4 #  4 bytes each
    size = {'position' : 3 , 'color': 4, 'texcoord': 2} # size in float of position/texcoord
    offset = {'position' : 0, 'color': 12, 'texcoord': 28 } # offsets in np array in bytes
 
    def __init__(self, position: QVector3D, color: QVector4D, texcoord: QVector2D):
        self.position = position
        self.color = color
        self.texcoord = texcoord
  
  
class Scene():
    '''
    A cube with 24 vertices "not shared"
    '''
    def __init__(self):
        self.nb_float = 0
        self.nb_int = 0
    
        vtype = [('position', np.float32, 3),
                 ('color', np.float32, 4),
                 ('texcoord', np.float32, 2)]
        itype = np.uint32
            
        # 8 points constituting a cube
        p = np.array([[1, 1, 1], [-1, 1, 1], [-1, -1, 1], [1, -1, 1],
                  [1, -1, -1], [1, 1, -1], [-1, 1, -1], [-1, -1, -1]],
                  dtype=float)
    
        # the colors on the points
                c = np.array([[0,1,1,1], [0,0,1,1], [0,0,0,1], [0,1,0,1],
                  [1,1,0,1], [1,1,1,1], [1,0,1,1], [1,0,0,1]],
                  dtype=float)
    
        # Texture coords
        t = np.array([[0, 0], [0, 1], [1, 1], [1, 0]])
    
        # the 24 nodes for the faces, 4 for each face - their coords is given with the p array (of length 8)
                faces_p = [0, 1, 2, 3,   0, 3, 4, 5,   0, 5, 6, 1,   1, 6, 7, 2,   7, 4, 3, 2,    4, 7, 6, 5]
        # the 24 nodes for the texture, 4 for each face - their coords is given with the t array (of length 4) - the 4 corner of the image
                faces_t = [0, 1, 2, 3,   0, 1, 2, 3,   0, 1, 2, 3,   3, 2, 1, 0,   0, 1, 2, 3,    0, 1, 2, 3]
    
        # list of vertices : 6 faces with for each 4 vertices : use faces_p indexes 
        self.vertices = np.zeros(24, vtype)
        self.vertices['position'] = p[faces_p]
        self.vertices['color'] = c[faces_p]
        self.vertices['texcoord'] = t[faces_t]
    
        print(self.vertices)
    
        # index buffer - of size 36 = 12 triangles * 3 nodes
        self.filled = np.resize(np.array([0, 1, 2, 0, 2, 3], dtype=itype), 6 * (2 * 3))
        self.filled += np.repeat(4 * np.arange(6, dtype=itype), 6)
    
        self.nb_float = 24 * Vertex.nb_float
        self.nb_int = 36
    
        self.textureData = QImage("./crate.png")
    
    def const_vertex_data(self):
        return self.vertices.tobytes()
    
    def const_index_data(self):
        return self.filled.tobytes()
    
class GLWidget(QOpenGLWidget, QOpenGLFunctions):
    vertex_code_only_color = """
    uniform mat4   model;
    uniform mat4   view;
    uniform mat4   projection;
    attribute vec3 position;
    attribute vec4 color;
    varying vec4   v_color;
    
    void main()
    {
        gl_Position = projection * view * model * vec4(position, 1.0);
    
        v_color = color;
    }  """
    
    fragment_code_only_color = """
    varying vec4 v_color;
    void main() { gl_FragColor = v_color; } """
    
    vertex_code_tex = """
    uniform mat4   model;
    uniform mat4   view;
    uniform mat4   projection;
    attribute vec3 position;
    attribute vec2 texcoord;   // Vertex texture coordinates
    varying vec2   v_texcoord;   // Interpolated fragment texture coordinates (out)
    
    void main()
    {
        // Assign varying variables
        v_texcoord  = texcoord;
    
        // Final position
        gl_Position = projection * view * model * vec4(position,1.0);
    } """
    
    fragment_code_tex = """
    uniform sampler2D texture; // Texture
    varying vec2 v_texcoord;   // Interpolated fragment texture coordinates (in)
    void main()
    {
        // Get texture color
        gl_FragColor = texture2D(texture, v_texcoord);
    } """
    
    float_size = ctypes.sizeof(ctypes.c_float) # 4 bytes
    int_size = ctypes.sizeof(ctypes.c_uint32) # 4 bytes
    
    def __init__(self, parent=None):
        QOpenGLWidget.__init__(self, parent)
        QOpenGLFunctions.__init__(self)
    
        self.scene = Scene()
        self.vao = QOpenGLVertexArrayObject()
        self.vbo = QOpenGLBuffer()
        self.ibo = QOpenGLBuffer()
        self.texture = QOpenGLTexture(QOpenGLTexture.Target2D)
        self.program = QOpenGLShaderProgram()
    
        self.proj = QMatrix4x4()
        self.proj.setToIdentity()
        self.view = QMatrix4x4()
        self.view.setToIdentity()
        self.view.translate(QVector3D(0,0,-5))
        self.model = QMatrix4x4()
        self.model.setToIdentity()
    
        self.theta = 0.0 # degrees
        self.phi = 0.0 # degrees
    
        self.timer = 0
    
        id = self.startTimer(1) 
    
    def sizeHint(self):
        return QSize(400, 400)
    
    def cleanup(self):
        self.makeCurrent()
        self.vbo.destroy()
        #self.ibo.destroy()
        del self.program
        self.program = None
        self.doneCurrent()
    
    def initializeGL(self):
        self.context().aboutToBeDestroyed.connect(self.cleanup)
        self.initializeOpenGLFunctions()
        self.glClearColor(0, 0, 0, 0)
    
        self.program = QOpenGLShaderProgram()
    
        #self.program.addShaderFromSourceCode(QOpenGLShader.Vertex, self.vertex_code_only_color)
        #self.program.addShaderFromSourceCode(QOpenGLShader.Fragment, self.fragment_code_only_color)
        self.program.addShaderFromSourceCode(QOpenGLShader.Vertex, self.vertex_code_tex)
        self.program.addShaderFromSourceCode(QOpenGLShader.Fragment, self.fragment_code_tex)
        self.program.link()
    
        self.program.bind()
    
        self.vao.create()
        vao_binder = QOpenGLVertexArrayObject.Binder(self.vao)
    
        self.vbo.create() # QOpenGLBuffer.VertexBuffer
        self.vbo.bind()
        self.vbo.allocate(self.scene.const_vertex_data(), self.scene.nb_float * self.float_size)
    
        self.ibo.create() # QOpenGLBuffer.IndexBuffer
        self.ibo.bind()
        self.ibo.allocate(self.scene.const_index_data(), self.scene.nb_int * self.int_size)
    
        # -------------------------------------------------------------------------------------
        # # ------------------------- the texture ---------------------------------------------
        self.texture.create()
        # Wrap style
        self.texture.setWrapMode(QOpenGLTexture.ClampToBorder)
    
        # Texture Filtering
        self.texture.setMinificationFilter(QOpenGLTexture.NearestMipMapLinear)
        self.texture.setMagnificationFilter(QOpenGLTexture.Linear)
    
        # Kopiere Daten in Texture und Erstelle Mipmap
        self.texture.setData(self.scene.textureData)
        # -------------------------------------------------------------------------------------
        # -------------------------------------------------------------------------------------
    
        self.setup_vertex_attribs()
    
        self.program.release()
        vao_binder = None
    
    def setup_vertex_attribs(self):
        self.vbo.bind()
  
        modelLocation = self.program.uniformLocation("model")
        self.program.setUniformValue(modelLocation, self.model)
    
        projLocation = self.program.uniformLocation("projection")
        self.program.setUniformValue(projLocation, self.proj)
    
        viewLocation = self.program.uniformLocation("view")
        self.program.setUniformValue(viewLocation, self.view)
    
        # Offset for position
        offset = Vertex.offset['position']
        size = Vertex.size['position'] # nb float in a position "packet" 
        stride = Vertex.bytes_size # nb bytes in a vertex 
    
        vertexLocation = self.program.attributeLocation("position")
        self.program.enableAttributeArray(vertexLocation)
        self.program.setAttributeBuffer(vertexLocation, GL.GL_FLOAT, offset, size, stride)
    
        # Offset for color
        offset = Vertex.offset['color'] # size in bytes of preceding data (position = QVector3D)
        size = Vertex.size['color'] # nb float in a color "packet" 
        stride = Vertex.bytes_size # nb bytes in a vertex
    
        colorLocation =  self.program.attributeLocation("color")
        self.program.enableAttributeArray(colorLocation)
        self.program.setAttributeBuffer(colorLocation, GL.GL_FLOAT, offset, size, stride)
    
        # Offset for texcoord
        offset = Vertex.offset['texcoord'] # size in bytes of preceding data (position = QVector3D + color = QVector4D)
        size = Vertex.size['texcoord'] # nb float in a texcoord "packet" 
        stride = Vertex.bytes_size # nb bytes in a vertex 
    
        texcoordLocation =  self.program.attributeLocation("texcoord")
        self.program.enableAttributeArray(texcoordLocation)
        self.program.setAttributeBuffer(texcoordLocation, GL.GL_FLOAT, offset, size, stride)
    
        # --------------------------------- the texture ------------------------------------------
        # uniform for fragment texture
        textureLocationID = self.program.uniformLocation("texture")
        self.program.setUniformValue(textureLocationID, 0) # the index of the texture
        # --------------------------------- the texture ------------------------------------------
    
        self.vbo.release()
   
    def paintGL(self):
        self.glClear(GL.GL_COLOR_BUFFER_BIT | GL.GL_DEPTH_BUFFER_BIT)
        self.glEnable(GL.GL_DEPTH_TEST)
           
        vao_binder = QOpenGLVertexArrayObject.Binder(self.vao)
        self.program.bind()
            
        modelLocation = self.program.uniformLocation("model")
        self.program.setUniformValue(modelLocation, self.model)
    
        projLocation = self.program.uniformLocation("projection")
        self.program.setUniformValue(projLocation, self.proj)
    
        viewLocation = self.program.uniformLocation("view")
        self.program.setUniformValue(viewLocation, self.view)
    
        # --------------------------------------------------------------------------------------------------------
        # --------------------------------------------------------------------------------------------------------
        self.texture.bind(0) # bind texture to texture index i -&gt; accessible in fragment shader through "texture"
        # --------------------------------------------------------------------------------------------------------
        # --------------------------------------------------------------------------------------------------------
    
        # Filled cube
        self.glDrawElements(GL.GL_TRIANGLES, 12*3, GL.GL_UNSIGNED_INT, self.scene.const_index_data())
    
        self.program.release()
        vao_binder = None
    
    def resizeGL(self, width, height):
        ratio = width / float(height)
        self.proj.perspective(45.0, ratio, 2.0, 100.0)
    
    def timerEvent(self, event):
        self.timer += 0.25 * math.pi/180.0
            
        # Make cube rotate
        self.theta += 1.0 # degrees
        self.phi += 1.0 # degrees
            
        self.model = QMatrix4x4()
        self.model.setToIdentity()
        self.model.rotate(self.theta, 0, 0, 1)
        self.model.rotate(self.phi, 0, 1, 0)
            
        self.update()</code></pre>
</div>

<p>Authors of openGL books always suggest how easy it is to use textures. I am
not quite this opinion...</p>

<p>So the full code is given here. Numpy arrays are used, and this makes the
code compact. Be sure to understand the numpy notation.</p>

<p>I have also kept the color defs from the previous example so that I can
switch between color and textures in the python program.</p>

<p>Because of the texture, the vertices cannot be shared anymore among all
triangles. Why? Because for 1 triangle, a given node may be mapped to the
texture coordinate [0,0], while for another triangle sharing the same node, the
node may need the texture coordinate [1,1]. Nevertheless, a certain amount of
"shared" nodes is still possible. On a face (4 nodes), nodes may be shared by
the 2 triangles of the face. We need indeed the texture on the 6 faces so we
need 6*4 vertices.</p>

<p>The Vertex class thus still contains the color def, and the texture def is
added. Because of the usage of numpy array features, there is no need anymore
of our method <code>toNumpyArray</code>. The numpy array is setup on the fly,
but the <strong>Vertex</strong> class still define the stride, positions and
offsets.</p>

<p>The array <code>self.vertices</code> will be our vertex buffer, while the
array <code>self.filled</code> will be the index buffer. What exactly the index
buffer contains? Well you can print out the index buffer in the console...</p>
<pre>&gt;&gt;&gt; filled = np.resize(np.array([0, 1, 2, 0, 2, 3], dtype=itype), 6 * (2 * 3))
&gt;&gt;&gt; filled
array([0, 1, 2, 0, 2, 3, 0, 1, 2, 0, 2, 3, 0, 1, 2, 0, 2, 3, 0, 1, 2, 0,
       2, 3, 0, 1, 2, 0, 2, 3, 0, 1, 2, 0, 2, 3], dtype=uint32)
&gt;&gt;&gt; filled += np.repeat(4 * np.arange(6, dtype=itype), 6)
&gt;&gt;&gt; filled
array([  0,  1,  2,    0,  2,  3,   
         4,  5,  6,    4,  6,  7, 
         8,  9, 10,    8, 10, 11, 
        12, 13, 14,   12, 14, 15,
        16, 17, 18,   16, 18, 19, 
        20, 21, 22,   20, 22, 23], dtype=uint32)
&gt;&gt;&gt;</pre>

<p>This is the definitions of the 12 triangles, each of them having 3 nodes.
There are 36 indices in total (array on length 36), for a total of 24 different nodes. 
Two triangles on the same face do share nodes.</p>

<p>We recognize the pattern: the 24 nodes are "virtually packed" in 6 groups (6 faces)
of 6 nodes. Each group of 6 nodes allows the defintion for 2 triangles, 
with these 2 triangles sharing 4 real nodes: the 4 nodes of a face.</p>


<p>The vertex buffer and index buffer are allocated/created as usual in the
<strong><code>initializeGL</code></strong> function, as well as the texture
object. Qt API allows here a user friendly notation.</p>

<p>At the end of <strong><code>initializeGL</code></strong>, the
setup_vertex_attribs is also called (as usual) and this time the
offsets/position for the texture is also given. Moreover, a <strong>texture
ID</strong> must be specified and written to the shader program at the texture
uniform "location" (as defined in the shader fragment program)</p>
<pre style="background: #f2f2f2;"><code class="language-python"># --------------------------------- the texture ------------------------------------------
# uniform for fragment texture
textureLocationID = self.program.uniformLocation("texture")
self.program.setUniformValue(textureLocationID, 0) # the index of the texture
# --------------------------------- the texture ------------------------------------------</code></pre>

<p>Be sure to call this at the right place!</p>

<p>Finally, in the <strong><code>paintGL</code></strong> method, we call as
usual the <strong><code>glDrawElements</code></strong> method, but before this
call have to bind the texture by its ID:</p>
<pre style="background: #f2f2f2;"><code class="language-python"># --------------------------------------------------------------------------------------------------------
# --------------------------------------------------------------------------------------------------------
self.texture.bind(0) # bind texture to texture index 0 -&gt; accessible in fragment shader through "texture"
# --------------------------------------------------------------------------------------------------------
# --------------------------------------------------------------------------------------------------------

# Filled cube
self.glDrawElements(GL.GL_TRIANGLES, 12*3, GL.GL_UNSIGNED_INT, self.scene.const_index_data())</code></pre>

<p>Simple, itsn't it! </p>

<p>Let's recapitulize: as in the previous example, the
<strong><code>glDrawElements</code></strong> method is used, with a somehow
different index buffer (because the list of vertices is different). But where
are exactly the differences? </p>

<p>Inside a vertex data, the <strong><code>textcoords</code></strong> have to
be specified instead of the <strong>color</strong> values.</p>

<p>For each of the 24 nodes, each node must have a texture coordinate, which
can be <code>[0,0], [0,1], [1,1]</code> or <code>[1,0]</code>. To do so, it was
easier to define groups of 4 nodes, each group for each side of the cube: The
numpy compact notation makes the whole somehow obscure...</p>
<!-- ----------------------------------------------------------------------------------------------------------->
<!-- ----------------------------------------------------------------------------------------------------------->

<h2 id="P-06">PySide6 - Handling the mouse</h2>
<h2 id="P-07">PySide6 - Simulation Widgets</h2>

<p>Infact quite straighforward: we have a "Simulation object" managing the time of the simulation. When the simulation's time changes,
(and thus the position of the model) a signal is emitted. The receiver helds the new model position from the simulation 
and inform the gl widget to redraw with this new position.</p>
</p>

<pre style="background: #f2f2f2;"><code class="language-python">
class Simulation(QtCore.QObject):
    '''
    '''
    current_time_changed = Signal(float)

    def __init__(self, parent, init_time, end_time, delta):
        QtCore.QObject.__init__(self)

        self.parent = parent
    
        self.init_time = init_time
        self.end_time = end_time
        self.delta = delta

        self.total_time = self.end_time - self.init_time

        self.current_time = self.init_time

        # translating the model during the simulation 
        self.model_position = QVector3D(0, 0, 0)

        self.set_current_time(self.end_time)
        self.current_time_changed.connect(self.parent.sim_time_changed)

        self.timer = QtCore.QTimer()
        self.timer.timeout.connect(self.run)
    
        self.timer_on = False
   
    def set_current_time(self, current_time):
        '''
        '''
        self.current_time = current_time
        self.model_position = QVector3D(
            math.sin(2* M_PI * (self.current_time / self.total_time)),
            -1 + math.cos( 2* M_PI * (self.current_time / self.total_time)),
            math.sin(2 * M_PI * (self.current_time / self.total_time))
        )

        self.current_time_changed.emit(self.current_time)

    def start_timer(self):
        if self.timer_on == False:
            self.timer_on = True
            self.timer.start(self.delta)

    def stop_timer(self):
        if self.timer_on == True:
            self.timer.stop()
            self.timer_on = False

    def run(self):
        '''
        callback on timer
        '''
        current_time = self.current_time + self.delta
    
        if current_time >= self.end_time:
            current_time = self.init_time

        self.set_current_time(current_time)
</code></pre>

<p>This is the code of the app main window: it contains the gl widget, the simulation widgets and the simulation object.
The simulation widgets talk to the simulation object, which gives back the signal when something in the simulation has changed.
On this signal, the main window inform the gl widget to update himself
</p>

<pre style="background: #f2f2f2;"><code class="language-python">class MainWindow(QMainWindow):
    '''
    '''
    update_gl_scene = Signal()

    def __init__(self, parent=None):
        QMainWindow.__init__(self, parent)

        self.layout = QtWidgets.QVBoxLayout()
        self.centralwidget = QtWidgets.QWidget()

        self.gl_widget = GLWidget()
        self.control = self.loadUi('simcontrolwidget.ui', self)

        self.layout.addWidget(self.gl_widget)
        self.layout.addWidget(self.control)

        self.centralwidget.setLayout(self.layout)
        self.setCentralWidget(self.centralwidget)
        self.setWindowTitle(self.tr("Hello GL"))

        self.control.pushButton_ToEnd.clicked.connect(self.OnSimToEnd)
        self.control.pushButton_Rewind.clicked.connect(self.OnSimRewind)
        self.control.pushButton_Run.clicked.connect(self.OnSimRun)
        self.control.pushButton_Pause.clicked.connect(self.OnSimPause)

        self.sim_start = 0
        self.sim_end = 10
        self.sim_delta = 0.1

        self.control.horizontalSlider_Position.valueChanged.connect(self.OnSimAtTime)
        self.control.horizontalSlider_Position.setMinimum(self.sim_start*1000)
        self.control.horizontalSlider_Position.setMaximum(self.sim_end*1000)
        self.control.horizontalSlider_Position.setSingleStep(1)
        
        self.simulation = Simulation(self, self.sim_start, self.sim_end, self.sim_delta)

        self.update_gl_scene.connect(self.update_gl)

    def update_gl(self):
        '''
        '''
        self.gl_widget.update()

    def sim_time_changed(self, simtime: float):
        '''
        The slot which is called when the simulation ticks
        '''
        self.control.horizontalSlider_Position.setValue(simtime*1000)

        # inform openGL to redraw
        # 1. set the new model position
        self.gl_widget.set_model_position(self.simulation.model_position)
        # 2. opegGL redraw
        self.update_gl_scene.emit()
</code></pre>

<h2 id="P-08">PySide6 - Moving the tool along the path</h2>
<h2 id="P-09">PySide6 - Simulating the milling process</h2>

<p>A brute force algorithm... I am quite interested about the performance... </p>

<p>So we define a "stock" of 1024x140 quadrats. For the height, the number of "z levels" in taken from the
g code. If there are for example 10 z levels, then I will define 1024x1024x10 voxels. Note that each voxel
consist of 12 triangles. The height of the voxels derives from the g cocde too.</p>

<p>Each voxel has a texture with an alpha channel. And each voxel "hit" by the toolpath should turn
invisible. So each voxel has an extra attribute "hit_time" when the toolpath effectively hits the voxel.
So the whole work consists in assigning each voxel of the stock an "hit_time" (with a texture).</p>

<!-- ----------------------------------------------------------------------------------------------------------->
<!-- ----------------------------------------------------------------------------------------------------------->


</div>
<script type="text/javascript">
var acc = document.getElementsByClassName("accordion");
var i;

for (i = 0; i < acc.length; i++) {
  acc[i].addEventListener("click", function() {
    this.classList.toggle("active");
    var panel = this.nextElementSibling;
    if (panel.style.display === "block") {
      panel.style.display = "none";
    } else {
      panel.style.display = "block";
    }
  });
}</script>
</body>
</html>
